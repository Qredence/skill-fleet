"""
FastAPI lifespan management for job persistence.

Handles:
1. Initialization of JobManager with database backing at startup
2. Background cleanup task to remove expired jobs from memory cache
3. Graceful shutdown
"""

from __future__ import annotations

import asyncio
import logging
from contextlib import asynccontextmanager, suppress
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from collections.abc import AsyncGenerator

    from fastapi import FastAPI

logger = logging.getLogger(__name__)


@asynccontextmanager
async def lifespan(app: FastAPI) -> AsyncGenerator[None, None]:
    """
    FastAPI lifespan context manager for startup/shutdown.

    Startup (before yield):
    - Initialize database and create tables
    - Initialize JobManager with database repository
    - Resume any pending jobs from database
    - Start background cleanup task for expired jobs

    Shutdown (after yield):
    - Cancel cleanup task
    - Close database connections
    """
    # =========================================================================
    # STARTUP
    # =========================================================================

    from ..db.database import SessionLocal, init_db
    from ..db.repositories import JobRepository
    from .services.job_manager import initialize_job_manager

    try:
        # Initialize database tables
        logger.info("Initializing database...")
        init_db()
        logger.info("‚úÖ Database tables created/verified")

        # Create a session and initialize JobManager with DB repo
        db_session = SessionLocal()
        job_repo = JobRepository(db_session)

        # Initialize JobManager with database backing
        initialize_job_manager(job_repo)
        logger.info("‚úÖ JobManager initialized with database persistence")

        # Initialize MLflow DSPy autologging
        from ..services.monitoring.mlflow_setup import setup_dspy_autologging
        from .config import get_settings

        settings = get_settings()
        if settings.mlflow_enabled:
            try:
                setup_dspy_autologging(
                    tracking_uri=settings.mlflow_tracking_uri,
                    experiment_name=settings.mlflow_experiment_name,
                )
                logger.info(
                    f"‚úÖ MLflow DSPy autologging enabled "
                    f"(experiment: {settings.mlflow_experiment_name})"
                )
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è MLflow autologging failed: {e}")

        # Resume any pending jobs from database
        pending_jobs = job_repo.get_by_status("pending")
        running_jobs = job_repo.get_by_status("running")
        pending_hitl_jobs = job_repo.get_by_status("pending_hitl")

        total_resumed = len(pending_jobs) + len(running_jobs) + len(pending_hitl_jobs)
        if total_resumed > 0:
            logger.info(f"üìã Resuming {total_resumed} jobs from database")
            logger.info(f"   - {len(pending_jobs)} pending")
            logger.info(f"   - {len(running_jobs)} running")
            logger.info(f"   - {len(pending_hitl_jobs)} waiting for human input")

    except Exception as e:
        logger.error(f"‚ùå Failed to initialize database/JobManager: {e}")
        raise

    # Start background cleanup task
    cleanup_task = asyncio.create_task(_cleanup_expired_jobs())
    logger.info("‚úÖ Background cleanup task started (runs every 5 minutes)")

    try:
        yield  # App runs here
    finally:
        # =====================================================================
        # SHUTDOWN
        # =====================================================================

        # Cancel cleanup task
        try:
            cleanup_task.cancel()
            with suppress(asyncio.CancelledError):
                await cleanup_task
            logger.info("‚úì Cleanup task cancelled")
        except Exception as e:
            logger.error(f"‚úó Failed to cancel cleanup task: {e}")

        # Close database connections
        try:
            from ..db.database import close_async_db, close_db

            close_db()
            await close_async_db()
            logger.info("‚úì Database connections closed")
        except Exception as e:
            logger.error(f"‚úó Failed to close database: {e}")

        logger.info("Shutdown complete")


async def _cleanup_expired_jobs() -> None:
    """
    Background task: Periodically clean up expired jobs from memory cache.

    Runs every 5 minutes. Removes jobs from memory that are older than the
    TTL (default: 60 minutes). These jobs remain in the database for durability.
    """
    from .services.job_manager import get_job_manager

    while True:
        try:
            await asyncio.sleep(300)  # 5 minutes
            manager = get_job_manager()
            cleaned = manager.cleanup_expired()

            if cleaned > 0:
                logger.info(f"üßπ Cleaned {cleaned} expired job(s) from memory cache")

        except asyncio.CancelledError:
            logger.debug("Cleanup task cancelled")
            break
        except Exception as e:
            logger.error(f"‚ùå Error in cleanup task: {e}", exc_info=True)
            # Continue on errors - cleanup is non-critical
